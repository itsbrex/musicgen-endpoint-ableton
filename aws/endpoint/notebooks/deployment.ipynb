{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment notebook\n",
    "\n",
    "This notebook is used to deploy the endpoint using the Sagemaker SDK, both locally and \n",
    "online. This is not meant to be the main source of endpoint provision, which should be\n",
    "done with terraform through the CD pipeline, but rather this is a way to test that\n",
    "everything works before provisioning it.\n",
    "\n",
    "It also register the model in the model registry for CD provisioning later.\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "**Note**: this notebook must be run outside of the `dev environment` container. This is \n",
    "because the sagemaker local development container can't spin up.\n",
    "\n",
    "The development workflow is as following: \n",
    "- All the development happens inside the dev container\n",
    "- Only when there is the need to run the notebook, this is run from another vscode \n",
    "window connected with ssh only\n",
    "- The `inference.py` script should be tested with their invidual functions, eg: as shown\n",
    "in the `aws/endpoint/src/tests/` folder. Once these work as expected, only then the you\n",
    "should execute the notebook. This is a huge time-saver, because the notebook can be\n",
    "very slow to run.\n",
    "\n",
    "---\n",
    "\n",
    "Before running the cells, make sure you login to AWS using either:\n",
    "\n",
    "- `aws configure sso` → for first time login\n",
    "- `aws sso login` → for all subsequent login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings, shared between local and online deployments\n",
    "# `model_image_uri` from https://github.com/aws/deep-learning-containers/blob/master/available_images.md \n",
    "\n",
    "model_name = \"ai-module-model\"\n",
    "model_entry_point = \"../src/code/inference.py\"\n",
    "model_data = \"../model/model.tar.gz\"\n",
    "model_image_uri = \"<image-uri>\"\n",
    "\n",
    "endpoint_name = \"endpoint-ai-module-0001-dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set local temp folder to avoid /tmp to become full\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root_dir = Path(os.getcwd()).parents[2].resolve()\n",
    "local_temp_folder_path = str(repo_root_dir / \".temp\" / \"sagemaker_local\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker[local]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: arn:aws:iam::138140302683:role/aws-reserved/sso.amazonaws.com/AWSReservedSSO_AdministratorAccess_6f1d7369dc867f6b\n",
      "Local temp folder path: /home/ubuntu/aws-ex-05/.temp/sagemaker_local\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "session = LocalSession()\n",
    "\n",
    "session.config = {\n",
    "    \"local\": {\n",
    "        \"local_code\": True,\n",
    "        \"container_root\": local_temp_folder_path,\n",
    "    }\n",
    "}\n",
    "\n",
    "session.settings = sagemaker.session_settings.SessionSettings(\n",
    "    local_download_dir = local_temp_folder_path\n",
    ")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(\"Role:\", role)\n",
    "print(\"Local temp folder path:\", local_temp_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HuggingFaceModel(\n",
    "    name=model_name,\n",
    "    role=role,\n",
    "    entry_point=model_entry_point,\n",
    "    model_data=model_data,\n",
    "    image_uri=model_image_uri,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"local_gpu\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "sagemaker_session.settings = sagemaker.session_settings.SessionSettings(\n",
    "    local_download_dir = local_temp_folder_path\n",
    ")\n",
    "\n",
    "role = \"arn:aws:iam::138140302683:role/service-role/AmazonSageMaker-ExecutionRole-20230522T162566\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: create the model\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    name=model_name,\n",
    "    role=role,\n",
    "    entry_point=model_entry_point,\n",
    "    model_data=model_data,\n",
    "    image_uri=model_image_uri,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.model.ModelPackage at 0x7f6bf15d3af0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2: register the model\n",
    "\n",
    "model.register(\n",
    "    model_package_group_name=\"ai-module-group-name\",\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.g4dn.xlarge\"],\n",
    "    approval_status=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# step 3: create endpoint\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = None # fill this \n",
    "\n",
    "response = predictor.predict(data=input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "endpoint_name = \"endpoint-image-generation-0001-dev\"\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/json\",\n",
    "    Body=json.dumps(input_data),\n",
    ")\n",
    "\n",
    "response_body = json.loads(response[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete endpoint \n",
    "# NOTE: this doesn't delete the model in the s3 bucket, nor it deletes the model from\n",
    "# model registry\n",
    "\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
